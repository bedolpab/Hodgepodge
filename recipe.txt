===========================================================
                       HDOGEPODGE
                JUST PREPARING FOR A ROLE !
===========================================================

What is this? Well, this is my interview prep material. Why
am I calling it Hodgepodge? Well, that's why, because I 
honestly do not know what will end up here. However, let's 
hope it plays into the next interview I take. It's all
related somehow though, i think (just trust me).

Oh, and I'll be writing them in Python, C, and Rust (trying).
That's gonna be fun.


>> LARGE LANGUAGE MODELS <<

While preparing to apply for AI-roles, many, in my experience,
are understanding how to use LLM-API wrappers to integrate
into existing softwareâ€”it is highly uncommon you'll be training
foundational models. That being said, you'll be interacting
with LLMs extensively, more if you're actually using any
fine-tuning tools, RAG, or any relevant techniques of sorts.

[Q-1]: What is tokenization? 

[A-1]: Tokenization, or tokenizing, is a process that occurs
       after prompting a model and before embeddings are
       created, which are the inputs to the model.

        PROMPT -> TOKENIZE(PROMPT) -> EMBBED(TOKENS)








