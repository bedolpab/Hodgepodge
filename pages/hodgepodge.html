<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hodgepodge</title>
    
    <link rel="stylesheet" href="../css/page.css">
    <link rel="stylesheet" href="../css/code.css">
    <link rel="stylesheet" href="../css/latex.css">
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Space+Mono:wght@400;700&display=swap" rel="stylesheet">
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <!-- Images are at ../figs/doc/* -->
    <div class="meta">
        <span><a href="../index.html">[ BACK ]</a></span>
        <span>Hodgepodge</span>
    </div>
    
    <h3> Hodgepodge? What? </h3>

    Yes, this will be domain specific (in some way), but I plan to store all my interview prep material here. Why am I calling it hodgepodge?
    Well, that's why, because I honestly do not know what will end up here. However, let's hope it plays well into my next role. It'll all be
    related together somehow (let's hope). Oh, and if any entry has or requires code, they'll all be in Python, C, or Rust. Why? I don't know,
    just deal with it.

    <h3> Large Language Models </h3>
    <p>
    Almost all of my professional experiences (internships) have been working with data or AI. I've found this is my comfort zone, and ontop of that,
    I'm good at it. One thing I've learned though, a lot of the fancy "AI" you see products lately are really just API-wrapped LLMs that ended up
    being integrated into the existing software. It's highly uncommon if you are in any of the roles doing what I just stated that you'll
    be training foundational models. That being said, it's very common to not understand how LLMs work extensively, and important skill I think
    all AI engineers should have. If you're working with RAG, fine-tuning, or any other techniques involving LLMs, understanding its inner workings
    does not hurt. 
    </p>


</body>
</html>
